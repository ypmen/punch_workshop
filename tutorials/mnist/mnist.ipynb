{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Punch Workshop 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This tutorial guides you through the process of converting a QKeras machine learning model into Vitis HLS code. You'll learn how to apply quantization-aware training (QAT) and model pruning using QKeras to optimize your model. Additionally, the tutorial covers the steps to transform the optimized model into Vitis HLS code using the HLS4ML framework, with a practical example using the MNIST dataset.\n",
    "\n",
    "## Requirements\n",
    "- tensorflow/qkeras (build the ML model)\n",
    "- HLS4ML (convert the QKeras model to HLS) https://github.com/fastmachinelearning/hls4ml\n",
    "- Vitis_HLS 2022.2 (complie the HLS code and export the IP)\n",
    "- Vitis/Vivado 2022.2 (generate the xclbin file that can run on Alveo card)\n",
    "- Xilinx Runtime (XRT is a low level communication layer (APIs and drivers) between the host and the card.) https://xilinx.github.io/XRT/2022.2/html/index.html\n",
    "- Development Target Platform (The deployment target platform is the communication layer physically implemented and flashed into the card.) https://www.xilinx.com/support/download/index.html/content/xilinx/en/downloadNav/alveo/u55c.html\n",
    "- pynq >3.0.1 (a Jupyter-based framework with Python APIs for using AMD Xilinx Adaptive Computing platforms) https://pynq.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import qkeras\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import datetime\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import numpy as np\n",
    "#import plotting\n",
    "%matplotlib inline\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed)\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "os.environ['PATH'] = '/home/ypmen/Data/Xilinx/Vitis_HLS/2022.2/bin:' + os.environ['PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "mnist = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images = (train_images) / 255.0\n",
    "test_images = (test_images) / 255.0\n",
    "\n",
    "train_images = train_images.reshape(train_images.shape[0], train_images.shape[1], train_images.shape[2], 1)\n",
    "test_images = test_images.reshape(test_images.shape[0], test_images.shape[1], test_images.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import *\n",
    "from qkeras import *\n",
    "# Define the model architecture\n",
    "model = keras.Sequential([\n",
    "\tQActivation(activation=quantized_bits(8, 2), input_shape=(28, 28, 1)),\n",
    "    QConv2D(8, 3, activation=quantized_bits(8, 2), kernel_quantizer=quantized_bits(8,2,alpha=1), bias_quantizer=quantized_bits(8,2,alpha=1), kernel_initializer='lecun_uniform'),\n",
    "\tQActivation(activation=quantized_relu(8, 2)),\n",
    "    QBatchNormalization(beta_quantizer=quantized_bits(32, 8), gamma_quantizer=quantized_bits(32, 8), mean_quantizer=quantized_bits(32, 8), variance_quantizer=quantized_bits(32, 8)),\n",
    "    QActivation(activation=quantized_bits(8, 2)),\n",
    "\tMaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'),\n",
    "    QConv2D(8, 3, activation=quantized_bits(8, 2), kernel_quantizer=quantized_bits(8,2,alpha=1), bias_quantizer=quantized_bits(8,2,alpha=1), kernel_initializer='lecun_uniform'),\n",
    "\tQActivation(activation=quantized_relu(8, 2)),\n",
    "    QBatchNormalization(beta_quantizer=quantized_bits(32, 8), gamma_quantizer=quantized_bits(32, 8), mean_quantizer=quantized_bits(32, 8), variance_quantizer=quantized_bits(32, 8)),\n",
    "    QActivation(activation=quantized_bits(8, 2)),\n",
    "\tMaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'),\n",
    "\tFlatten(),\n",
    "   \tQDense(10, kernel_quantizer=quantized_bits(8,2,alpha=1), bias_quantizer=quantized_bits(8,2,alpha=1), kernel_initializer='lecun_uniform'),\n",
    "    Softmax()\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# callbacks\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "checkpoint = ModelCheckpoint('chechpoint/test.h5', monitor='val_loss', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels), callbacks=[tensorboard_callback, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('mnist.h5')\n",
    "model = qkeras.utils.load_qmodel('mnist.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "pruning_params = {\n",
    "    'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(0.5, 0),\n",
    "    'block_size': (1, 1),\n",
    "    'block_pooling_type': 'AVG'\n",
    "}\n",
    "\n",
    "def apply_pruning(layer):\n",
    "  if isinstance(layer, QDense):\n",
    "    return tfmot.sparsity.keras.prune_low_magnitude(layer, **pruning_params)\n",
    "  elif isinstance(layer, QConv2D):\n",
    "    return tfmot.sparsity.keras.prune_low_magnitude(layer, **pruning_params)\n",
    "  return layer\n",
    "\n",
    "model_for_pruning = tf.keras.models.clone_model(\n",
    "    model,\n",
    "    clone_function=apply_pruning,\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "    # Log sparsity and other metrics in Tensorboard.\n",
    "    tfmot.sparsity.keras.PruningSummaries(log_dir=log_dir)\n",
    "]\n",
    "\n",
    "model_for_pruning.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_for_pruning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model_for_pruning.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#model = qkeras.utils.load_qmodel('mnist.h5')\n",
    "\n",
    "pred = model.predict(test_images)\n",
    "predicted = np.argmax(pred, axis=1)\n",
    "report = classification_report(test_labels, predicted)\n",
    "\n",
    "print(report)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "pred = model_for_pruning.predict(test_images)\n",
    "predicted = np.argmax(pred, axis=1)\n",
    "report = classification_report(test_labels, predicted)\n",
    "\n",
    "print(report)\n",
    "\n",
    "test_loss, test_acc = model_for_pruning.evaluate(test_images, test_labels)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HLS4ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hls4ml\n",
    "\n",
    "import yaml\n",
    "\n",
    "with open(\"config.yaml\", 'r') as ymlfile:\n",
    "\tconfig = yaml.safe_load(ymlfile)\n",
    "\n",
    "print(\"-----------------------------------\")\n",
    "print(\"Configuration\")\n",
    "print(\"-----------------------------------\")\n",
    "hls_model = hls4ml.converters.convert_from_keras_model(model,\n",
    "                                                       hls_config=config,\n",
    "                                                       output_dir='model_1/hls4ml_prj',\n",
    "                                                       part='xcu55c-fsvh2892-2L-e',\n",
    "                                                       io_type='io_stream',\n",
    "                                                       backend='Vitis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hls4ml.utils.plot_model(hls_model, show_shapes=True, show_precision=True, to_file=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_keras = np.argmax(model.predict(test_images), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_hls = np.argmax(hls_model.predict(test_images), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Keras  Accuracy: {}\".format(accuracy_score(test_labels, labels_keras)))\n",
    "print(\"hls4ml Accuracy: {}\".format(accuracy_score(test_labels, labels_hls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_model.predict(np.round(test_images[0:2]*2**5)/2**5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(len(labels_keras))[labels_keras != labels_hls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_model.build(csim=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hls4ml.report.read_vivado_report('model_1/hls4ml_prj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('model_1/hls4ml_prj/tb_data/tb_input_features.dat', (np.round(test_images[0]*2**5)/2**5).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('model_1/hls4ml_prj/tb_data/tb_output_predictions.dat', hls_model.predict(np.round(test_images[0:2]*2**5)/2**5)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (np.round(test_images[0]*2**5)/2**5).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[np.arange(len(a))[a != 0]]*32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hls4ml-tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
